import { useState, useEffect, useRef } from 'react';
import { lipsyncManager } from '../App';
import { VISEMES } from 'wawa-lipsync';

export const TextToSpeech = () => {
    const [text, setText] = useState('Xin ch√†o! T√¥i l√† AI avatar. H√£y nh·∫≠p vƒÉn b·∫£n ƒë·ªÉ t√¥i ƒë·ªçc.');
    const [isPlaying, setIsPlaying] = useState(false);
    const [voices, setVoices] = useState([]);
    const [selectedVoice, setSelectedVoice] = useState('');
    const [rate, setRate] = useState(0.9);
    const [pitch, setPitch] = useState(1.0);
    const [volume, setVolume] = useState(1.0);
    const [enableFakeLipsync, setEnableFakeLipsync] = useState(true);
    
    // Speech-to-Text states
    const [isRecording, setIsRecording] = useState(false);
    const [isProcessing, setIsProcessing] = useState(false);
    const [recordingTime, setRecordingTime] = useState(0);
    const [selectedLanguage, setSelectedLanguage] = useState('vi-VN');
    const [transcriptionResult, setTranscriptionResult] = useState(null);
    const [apiServerStatus, setApiServerStatus] = useState('unknown');
    
    const audioRef = useRef(null);
    const mediaRecorderRef = useRef(null);
    const mediaStreamRef = useRef(null);
    const chunksRef = useRef([]);
    const fakeLipsyncRef = useRef(null);
    const speechUtteranceRef = useRef(null);
    const recordingTimerRef = useRef(null);

    // Load available voices
    useEffect(() => {
        const updateVoices = () => {
            const availableVoices = speechSynthesis.getVoices();
            setVoices(availableVoices);

            // T√¨m voice ti·∫øng Vi·ªát
            const vietnameseVoice = availableVoices.find(voice =>
                voice.lang.includes('vi') || voice.name.includes('Vietnamese')
            );

            if (vietnameseVoice) {
                setSelectedVoice(vietnameseVoice.name);
            } else {
                // Fallback to English or first available voice
                const englishVoice = availableVoices.find(voice =>
                    voice.lang.includes('en')
                );
                setSelectedVoice(englishVoice ? englishVoice.name : availableVoices[0]?.name || '');
            }
        };

        updateVoices();
        speechSynthesis.addEventListener('voiceschanged', updateVoices);

        return () => {
            speechSynthesis.removeEventListener('voiceschanged', updateVoices);
        };
    }, []);

    // Check API server status
    useEffect(() => {
        const checkApiStatus = async () => {
            try {
                const response = await fetch('http://localhost:5000/health');
                const data = await response.json();
                setApiServerStatus(data.speech_client_ready ? 'ready' : 'no-credentials');
            } catch (error) {
                setApiServerStatus('offline');
            }
        };

        checkApiStatus();
        const interval = setInterval(checkApiStatus, 30000); // Check every 30 seconds

        return () => clearInterval(interval);
    }, []);

    // Speech-to-Text Functions
    const startRecording = async () => {
        try {
            // Request microphone permission
            const stream = await navigator.mediaDevices.getUserMedia({ 
                audio: {
                    echoCancellation: true,
                    noiseSuppression: true,
                    sampleRate: 16000
                } 
            });
            
            mediaStreamRef.current = stream;
            
            // Create MediaRecorder
            const mediaRecorder = new MediaRecorder(stream, {
                mimeType: 'audio/webm;codecs=opus'
            });
            
            mediaRecorderRef.current = mediaRecorder;
            chunksRef.current = [];
            
            mediaRecorder.ondataavailable = (event) => {
                if (event.data.size > 0) {
                    chunksRef.current.push(event.data);
                }
            };
            
            mediaRecorder.onstop = async () => {
                const audioBlob = new Blob(chunksRef.current, { type: 'audio/webm;codecs=opus' });
                await processRecording(audioBlob);
                
                // Clean up
                if (mediaStreamRef.current) {
                    mediaStreamRef.current.getTracks().forEach(track => track.stop());
                    mediaStreamRef.current = null;
                }
            };
            
            // Start recording
            mediaRecorder.start(100); // Collect data every 100ms
            setIsRecording(true);
            setRecordingTime(0);
            setTranscriptionResult(null);
            
            // Start timer
            recordingTimerRef.current = setInterval(() => {
                setRecordingTime(prev => prev + 1);
            }, 1000);
            
            console.log('üé§ B·∫Øt ƒë·∫ßu ghi √¢m...');
            
        } catch (error) {
            console.error('‚ùå L·ªói khi b·∫Øt ƒë·∫ßu ghi √¢m:', error);
            alert('Kh√¥ng th·ªÉ truy c·∫≠p microphone. Vui l√≤ng cho ph√©p tr√¨nh duy·ªát s·ª≠ d·ª•ng microphone.');
        }
    };
    
    const stopRecording = () => {
        if (mediaRecorderRef.current && mediaRecorderRef.current.state !== 'inactive') {
            mediaRecorderRef.current.stop();
        }
        
        setIsRecording(false);
        
        if (recordingTimerRef.current) {
            clearInterval(recordingTimerRef.current);
            recordingTimerRef.current = null;
        }
        
        console.log('‚èπÔ∏è D·ª´ng ghi √¢m');
    };
    
    const processRecording = async (audioBlob) => {
        setIsProcessing(true);
        
        try {
            console.log('üîÑ ƒêang x·ª≠ l√Ω audio blob...');
            
            // Convert blob to base64
            const reader = new FileReader();
            reader.onload = async () => {
                const audioData = reader.result;
                
                try {
                    // Send to Speech-to-Text API
                    const response = await fetch('http://localhost:5000/transcribe-blob', {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json',
                        },
                        body: JSON.stringify({
                            audioData: audioData,
                            language: selectedLanguage,
                            sampleRate: 16000
                        })
                    });
                    
                    const result = await response.json();
                    
                    if (result.success && result.full_transcript) {
                        console.log('‚úÖ Transcription th√†nh c√¥ng:', result.full_transcript);
                        setTranscriptionResult(result);
                        
                        // Auto-fill text area
                        const shouldReplace = window.confirm(
                            `Phi√™n √¢m th√†nh c√¥ng!\n\n"${result.full_transcript}"\n\nB·∫°n c√≥ mu·ªën thay th·∫ø vƒÉn b·∫£n hi·ªán t·∫°i kh√¥ng?`
                        );
                        
                        if (shouldReplace) {
                            setText(result.full_transcript);
                        }
                    } else {
                        console.error('‚ùå Transcription th·∫•t b·∫°i:', result.error);
                        setTranscriptionResult({ error: result.error || 'Kh√¥ng th·ªÉ chuy·ªÉn ƒë·ªïi gi·ªçng n√≥i sang vƒÉn b·∫£n' });
                    }
                } catch (apiError) {
                    console.error('‚ùå L·ªói API:', apiError);
                    setTranscriptionResult({ error: 'L·ªói k·∫øt n·ªëi ƒë·∫øn server Speech-to-Text. Vui l√≤ng ki·ªÉm tra server c√≥ ƒëang ch·∫°y kh√¥ng.' });
                }
            };
            
            reader.readAsDataURL(audioBlob);
            
        } catch (error) {
            console.error('‚ùå L·ªói x·ª≠ l√Ω recording:', error);
            setTranscriptionResult({ error: 'L·ªói x·ª≠ l√Ω file ghi √¢m' });
        } finally {
            setIsProcessing(false);
        }
    };
    
    const formatRecordingTime = (seconds) => {
        const minutes = Math.floor(seconds / 60);
        const remainingSeconds = seconds % 60;
        return `${minutes}:${remainingSeconds.toString().padStart(2, '0')}`;
    };
    // Simple direct viseme update approach
    const startDirectVisemeUpdate = (textContent, speechRate) => {
        if (!enableFakeLipsync || !lipsyncManager) return;

        console.log('üéØ B·∫Øt ƒë·∫ßu direct viseme update');

        // Create word sequence
        const words = textContent.split(/[\s.,!?;:-]+/).filter(word => word.length > 0);
        console.log(`üìù Direct update cho ${words.length} t·ª´:`, words);

        let wordIndex = 0;
        const wordDuration = 800; // Fixed duration per word
        const pauseDuration = 200; // Pause between words

        // Clear any existing interval
        if (fakeLipsyncRef.current) {
            clearInterval(fakeLipsyncRef.current);
        }

        const updateViseme = () => {
            if (wordIndex >= words.length) {
                // Finished - set to silence
                lipsyncManager.viseme = VISEMES.sil;
                if (fakeLipsyncRef.current) {
                    clearInterval(fakeLipsyncRef.current);
                    fakeLipsyncRef.current = null;
                }
                console.log('‚úÖ Direct viseme update ho√†n th√†nh');
                return;
            }

            const word = words[wordIndex].toLowerCase();
            const firstChar = word[0];
            let viseme = VISEMES.aa; // Default

            // Map character to viseme
            if ('a√°√†·∫£√£·∫°ƒÉ·∫Ø·∫±·∫≥·∫µ·∫∑√¢·∫•·∫ß·∫©·∫´·∫≠'.includes(firstChar)) {
                viseme = VISEMES.aa;
            } else if ('e√©√®·∫ª·∫Ω·∫π√™·∫ø·ªÅ·ªÉ·ªÖ·ªá'.includes(firstChar)) {
                viseme = VISEMES.E;
            } else if ('i√≠√¨·ªâƒ©·ªã'.includes(firstChar)) {
                viseme = VISEMES.I;
            } else if ('o√≥√≤·ªè√µ·ªç√¥·ªë·ªì·ªï·ªó·ªô∆°·ªõ·ªù·ªü·ª°·ª£'.includes(firstChar)) {
                viseme = VISEMES.O;
            } else if ('u√∫√π·ªß≈©·ª•∆∞·ª©·ª´·ª≠·ªØ·ª±'.includes(firstChar)) {
                viseme = VISEMES.U;
            } else if ('bpmw'.includes(firstChar)) {
                viseme = VISEMES.PP;
            } else if ('fv'.includes(firstChar)) {
                viseme = VISEMES.FF;
            } else if ('dt'.includes(firstChar)) {
                viseme = VISEMES.DD;
            } else if ('kgc'.includes(firstChar)) {
                viseme = VISEMES.kk;
            } else if ('sz'.includes(firstChar)) {
                viseme = VISEMES.SS;
            } else if ('n'.includes(firstChar)) {
                viseme = VISEMES.nn;
            } else if ('rlx'.includes(firstChar)) {
                viseme = VISEMES.RR;
            } else if ('jy'.includes(firstChar)) {
                viseme = VISEMES.CH;
            }

            // DIRECT UPDATE - bypass all lipsync logic
            const oldViseme = lipsyncManager.viseme;
            lipsyncManager.viseme = viseme;

            console.log(`üéØ DIRECT: "${word}" [${firstChar}] ‚Üí ${oldViseme} ‚ûú ${viseme}`);

            wordIndex++;

            // Schedule pause and next word
            setTimeout(() => {
                if (lipsyncManager) {
                    lipsyncManager.viseme = VISEMES.sil;
                    console.log(`‚è∏Ô∏è Pause after "${word}"`);
                }
            }, wordDuration);
        };

        // Start immediately and repeat for each word
        updateViseme();
        fakeLipsyncRef.current = setInterval(updateViseme, wordDuration + pauseDuration);
    };

    const speakText = async () => {
        if (!text.trim()) return;

        // Debug: Ki·ªÉm tra lipsyncManager
        console.log('üîç Ki·ªÉm tra lipsyncManager:', {
            exists: !!lipsyncManager,
            type: typeof lipsyncManager,
            viseme: lipsyncManager?.viseme,
            features: !!lipsyncManager?.features,
            processAudio: typeof lipsyncManager?.processAudio
        });

        // Stop any current speech and fake lipsync
        speechSynthesis.cancel();
        if (fakeLipsyncRef.current) {
            clearInterval(fakeLipsyncRef.current);
            fakeLipsyncRef.current = null;
        }

        setIsPlaying(true);

        try {
            // Create speech utterance
            const utterance = new SpeechSynthesisUtterance(text);
            speechUtteranceRef.current = utterance;

            // Set voice
            const voice = voices.find(v => v.name === selectedVoice);
            if (voice) {
                utterance.voice = voice;
            }

            // Set properties
            utterance.rate = rate;
            utterance.pitch = pitch;
            utterance.volume = volume;

            utterance.onstart = () => {
                console.log('üîä B·∫Øt ƒë·∫ßu ph√°t √¢m');
                // DON'T start fake lipsync here - already started immediately
                console.log('‚ÑπÔ∏è Fake lipsync ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o tr∆∞·ªõc ƒë√≥');
            };

            utterance.onend = () => {
                setIsPlaying(false);
                speechUtteranceRef.current = null;
                // Stop fake lipsync
                if (fakeLipsyncRef.current) {
                    clearInterval(fakeLipsyncRef.current);
                    fakeLipsyncRef.current = null;
                }
                if (lipsyncManager) {
                    lipsyncManager.viseme = VISEMES.sil;
                    if (lipsyncManager.features) {
                        lipsyncManager.features.volume = 0;
                    }
                }
                console.log('‚úÖ Ho√†n th√†nh ph√°t √¢m');
            };

            utterance.onerror = (error) => {
                setIsPlaying(false);
                speechUtteranceRef.current = null;
                // Stop fake lipsync on error
                if (fakeLipsyncRef.current) {
                    clearInterval(fakeLipsyncRef.current);
                    fakeLipsyncRef.current = null;
                }
                console.error('‚ùå L·ªói ph√°t √¢m:', error);
            };

            // Speak the text
            speechSynthesis.speak(utterance);

            // Start direct viseme update immediately (don't wait for onstart)
            if (enableFakeLipsync) {
                console.log('üéØ B·∫Øt ƒë·∫ßu direct viseme update ngay l·∫≠p t·ª©c...');
                startDirectVisemeUpdate(text, rate);
            }

        } catch (error) {
            console.error('L·ªói t·∫°o speech:', error);
            setIsPlaying(false);
        }
    };

    const stopSpeech = () => {
        speechSynthesis.cancel();
        setIsPlaying(false);
        speechUtteranceRef.current = null;

        // Stop direct viseme update
        if (fakeLipsyncRef.current) {
            clearInterval(fakeLipsyncRef.current);
            fakeLipsyncRef.current = null;
            console.log('‚èπÔ∏è ƒê√£ d·ª´ng direct viseme update');
        }

        // Reset lipsync manager
        if (lipsyncManager) {
            lipsyncManager.viseme = VISEMES.sil;
            if (lipsyncManager.features) {
                lipsyncManager.features.volume = 0;
            }
            console.log('üîÑ Reset lipsyncManager v·ªÅ silence');
        }

        if (audioRef.current) {
            audioRef.current.pause();
            audioRef.current.currentTime = 0;
        }
    };

    // Cleanup on unmount
    useEffect(() => {
        return () => {
            if (fakeLipsyncRef.current) {
                clearInterval(fakeLipsyncRef.current);
            }
            if (speechUtteranceRef.current) {
                speechSynthesis.cancel();
            }
            if (recordingTimerRef.current) {
                clearInterval(recordingTimerRef.current);
            }
            if (mediaStreamRef.current) {
                mediaStreamRef.current.getTracks().forEach(track => track.stop());
            }
        };
    }, []);

    const predefinedTexts = [
        "Xin ch√†o! T√¥i l√† AI avatar c·ªßa b·∫°n.",
        "T√¥i c√≥ th·ªÉ ƒë·ªìng b·ªô m√¥i v·ªõi gi·ªçng n√≥i m·ªôt c√°ch t·ª± nhi√™n.",
        "H√£y th·ª≠ nh·∫≠p vƒÉn b·∫£n kh√°c ƒë·ªÉ xem t√¥i ho·∫°t ƒë·ªông.",
        "C√¥ng ngh·ªá lipsync n√†y s·ª≠ d·ª•ng Web Audio API.",
        "B·∫°n c√≥ th·ªÉ ƒëi·ªÅu ch·ªânh t·ªëc ƒë·ªô, cao ƒë·ªô v√† √¢m l∆∞·ª£ng.",
        "Ch√∫c b·∫°n c√≥ tr·∫£i nghi·ªám th√∫ v·ªã v·ªõi AI avatar!"
    ];

    const languageOptions = [
        { code: 'vi-VN', name: 'Ti·∫øng Vi·ªát' },
        { code: 'en-US', name: 'English (US)' },
        { code: 'en-GB', name: 'English (UK)' },
        { code: 'zh-CN', name: '‰∏≠Êñá (ÁÆÄ‰Ωì)' },
        { code: 'ja-JP', name: 'Êó•Êú¨Ë™û' },
        { code: 'ko-KR', name: 'ÌïúÍµ≠Ïñ¥' },
        { code: 'fr-FR', name: 'Fran√ßais' },
        { code: 'de-DE', name: 'Deutsch' },
        { code: 'es-ES', name: 'Espa√±ol' },
    ];

    return (
        <div className="p-4 bg-white rounded-lg shadow-lg space-y-6">
            <h3 className="text-xl font-bold text-gray-800">üé§ Speech-to-Text & Text-to-Speech</h3>

            {/* API Server Status */}
            <div className="p-3 rounded-md border">
                <div className="flex items-center space-x-2">
                    <div className={`w-3 h-3 rounded-full ${
                        apiServerStatus === 'ready' ? 'bg-green-500' :
                        apiServerStatus === 'no-credentials' ? 'bg-yellow-500' :
                        'bg-red-500'
                    }`}></div>
                    <span className="text-sm font-medium">
                        {apiServerStatus === 'ready' ? '‚úÖ API Server Ready' :
                         apiServerStatus === 'no-credentials' ? '‚ö†Ô∏è API Server Online (No Credentials)' :
                         '‚ùå API Server Offline'}
                    </span>
                </div>
                {apiServerStatus !== 'ready' && (
                    <p className="text-xs text-gray-600 mt-1">
                        {apiServerStatus === 'offline' 
                            ? 'Ch·∫°y: python speech_api.py ƒë·ªÉ kh·ªüi ƒë·ªông server'
                            : 'C·∫ßn c·∫•u h√¨nh Google Cloud credentials trong .env'}
                    </p>
                )}
            </div>

            {/* Speech-to-Text Section */}
            <div className="border rounded-lg p-4 bg-blue-50">
                <h4 className="text-lg font-semibold text-blue-800 mb-3">üéôÔ∏è Ghi √¢m gi·ªçng n√≥i ‚Üí VƒÉn b·∫£n</h4>
                
                {/* Language Selection */}
                <div className="mb-4">
                    <label className="block text-sm font-medium text-gray-700 mb-2">
                        Ng√¥n ng·ªØ nh·∫≠n d·∫°ng:
                    </label>
                    <select
                        value={selectedLanguage}
                        onChange={(e) => setSelectedLanguage(e.target.value)}
                        className="w-full p-2 border border-gray-300 rounded-md focus:ring-2 focus:ring-blue-500"
                        disabled={isRecording || isProcessing}
                    >
                        {languageOptions.map((lang) => (
                            <option key={lang.code} value={lang.code}>
                                {lang.name} ({lang.code})
                            </option>
                        ))}
                    </select>
                </div>

                {/* Recording Controls */}
                <div className="flex items-center space-x-3 mb-4">
                    {!isRecording ? (
                        <button
                            onClick={startRecording}
                            disabled={isProcessing || apiServerStatus !== 'ready'}
                            className="px-4 py-2 bg-red-600 text-white rounded-md hover:bg-red-700 disabled:bg-gray-400 disabled:cursor-not-allowed flex items-center space-x-2"
                        >
                            <span>üé§</span>
                            <span>B·∫Øt ƒë·∫ßu ghi √¢m</span>
                        </button>
                    ) : (
                        <button
                            onClick={stopRecording}
                            className="px-4 py-2 bg-gray-600 text-white rounded-md hover:bg-gray-700 flex items-center space-x-2"
                        >
                            <span>‚èπÔ∏è</span>
                            <span>D·ª´ng ghi √¢m</span>
                        </button>
                    )}

                    {isRecording && (
                        <div className="flex items-center space-x-2">
                            <div className="animate-pulse w-3 h-3 bg-red-500 rounded-full"></div>
                            <span className="text-sm font-medium text-red-600">
                                ƒêang ghi: {formatRecordingTime(recordingTime)}
                            </span>
                        </div>
                    )}

                    {isProcessing && (
                        <div className="flex items-center space-x-2">
                            <div className="animate-spin w-4 h-4 border-2 border-blue-600 border-t-transparent rounded-full"></div>
                            <span className="text-sm text-blue-600">ƒêang x·ª≠ l√Ω...</span>
                        </div>
                    )}
                </div>

                {/* Transcription Result */}
                {transcriptionResult && (
                    <div className="mt-4">
                        {transcriptionResult.error ? (
                            <div className="p-3 bg-red-100 border border-red-300 rounded-md">
                                <p className="text-sm text-red-700">
                                    ‚ùå L·ªói: {transcriptionResult.error}
                                </p>
                            </div>
                        ) : (
                            <div className="p-3 bg-green-100 border border-green-300 rounded-md">
                                <p className="text-sm font-medium text-green-700 mb-2">‚úÖ K·∫øt qu·∫£ nh·∫≠n d·∫°ng:</p>
                                <p className="text-green-800 font-medium">"{transcriptionResult.full_transcript}"</p>
                                {transcriptionResult.results && transcriptionResult.results[0] && (
                                    <p className="text-xs text-green-600 mt-1">
                                        ƒê·ªô tin c·∫≠y: {(transcriptionResult.results[0].confidence * 100).toFixed(1)}%
                                    </p>
                                )}
                                <button
                                    onClick={() => setText(transcriptionResult.full_transcript)}
                                    className="mt-2 px-3 py-1 bg-green-600 text-white text-sm rounded hover:bg-green-700"
                                >
                                    üìù S·ª≠ d·ª•ng vƒÉn b·∫£n n√†y
                                </button>
                            </div>
                        )}
                    </div>
                )}

                {/* Recording Tips */}
                <div className="mt-4 text-xs text-gray-600 bg-gray-50 p-2 rounded">
                    <p><strong>üí° M·∫πo ƒë·ªÉ ghi √¢m t·ªët:</strong></p>
                    <ul className="list-disc list-inside space-y-1 mt-1">
                        <li>N√≥i r√µ r√†ng v√† v·ªõi t·ªëc ƒë·ªô v·ª´a ph·∫£i</li>
                        <li>Gi·∫£m ti·∫øng ·ªìn xung quanh</li>
                        <li>ƒê·∫∑t micro g·∫ßn mi·ªáng (kho·∫£ng 10-15cm)</li>
                        <li>Ch·ªçn ng√¥n ng·ªØ ph√π h·ª£p v·ªõi n·ªôi dung b·∫°n n√≥i</li>
                    </ul>
                </div>
            </div>

            {/* Text-to-Speech Section */}
            <div className="border rounded-lg p-4 bg-green-50">
                <h4 className="text-lg font-semibold text-green-800 mb-3">üîä VƒÉn b·∫£n ‚Üí Gi·ªçng n√≥i</h4>

                {/* Text Input */}
                <div className="mb-4">
                    <label className="block text-sm font-medium text-gray-700 mb-2">
                        VƒÉn b·∫£n c·∫ßn ƒë·ªçc:
                    </label>
                    <textarea
                        value={text}
                        onChange={(e) => setText(e.target.value)}
                        className="w-full p-3 border border-gray-300 rounded-md focus:ring-2 focus:ring-green-500 focus:border-transparent resize-none"
                        rows={3}
                        placeholder="Nh·∫≠p vƒÉn b·∫£n ti·∫øng Vi·ªát ho·∫∑c ti·∫øng Anh..."
                    />
                </div>

                {/* Quick Text Buttons */}
                <div className="mb-4">
                    <label className="block text-sm font-medium text-gray-700 mb-2">
                        VƒÉn b·∫£n m·∫´u:
                    </label>
                    <div className="grid grid-cols-1 md:grid-cols-2 gap-2">
                        {predefinedTexts.map((preText, index) => (
                            <button
                                key={index}
                                onClick={() => setText(preText)}
                                className="p-2 text-left text-sm bg-gray-100 hover:bg-gray-200 rounded border transition-colors"
                            >
                                {preText.length > 50 ? preText.substring(0, 50) + '...' : preText}
                            </button>
                        ))}
                    </div>
                </div>

                {/* Voice Selection */}
                <div className="mb-4">
                    <label className="block text-sm font-medium text-gray-700 mb-2">
                        Gi·ªçng ƒë·ªçc:
                    </label>
                    <select
                        value={selectedVoice}
                        onChange={(e) => setSelectedVoice(e.target.value)}
                        className="w-full p-2 border border-gray-300 rounded-md focus:ring-2 focus:ring-green-500"
                    >
                        {voices.map((voice) => (
                            <option key={voice.name} value={voice.name}>
                                {voice.name} ({voice.lang}) {voice.default ? '(m·∫∑c ƒë·ªãnh)' : ''}
                            </option>
                        ))}
                    </select>
                </div>

                {/* Voice Controls */}
                <div className="grid grid-cols-1 md:grid-cols-3 gap-4 mb-4">
                    <div>
                        <label className="block text-sm font-medium text-gray-700 mb-1">
                            T·ªëc ƒë·ªô: {rate}
                        </label>
                        <input
                            type="range"
                            min="0.1"
                            max="2"
                            step="0.1"
                            value={rate}
                            onChange={(e) => setRate(parseFloat(e.target.value))}
                            className="w-full"
                        />
                    </div>
                    <div>
                        <label className="block text-sm font-medium text-gray-700 mb-1">
                            Cao ƒë·ªô: {pitch}
                        </label>
                        <input
                            type="range"
                            min="0"
                            max="2"
                            step="0.1"
                            value={pitch}
                            onChange={(e) => setPitch(parseFloat(e.target.value))}
                            className="w-full"
                        />
                    </div>
                    <div>
                        <label className="block text-sm font-medium text-gray-700 mb-1">
                            √Çm l∆∞·ª£ng: {volume}
                        </label>
                        <input
                            type="range"
                            min="0"
                            max="1"
                            step="0.1"
                            value={volume}
                            onChange={(e) => setVolume(parseFloat(e.target.value))}
                            className="w-full"
                        />
                    </div>
                </div>

                {/* Fake Lipsync Toggle */}
                <div className="mb-4">
                    <label className="flex items-center space-x-2">
                        <input
                            type="checkbox"
                            checked={enableFakeLipsync}
                            onChange={(e) => setEnableFakeLipsync(e.target.checked)}
                            className="rounded"
                        />
                        <span className="text-sm font-medium text-gray-700">
                            ü§ñ B·∫≠t ƒë·ªìng b·ªô m√¥i th√¥ng minh (Fake Lipsync)
                        </span>
                    </label>
                    <p className="text-xs text-gray-500 ml-6">
                        M√¥ ph·ªèng chuy·ªÉn ƒë·ªông m√¥i d·ª±a tr√™n n·ªôi dung vƒÉn b·∫£n khi s·ª≠ d·ª•ng Speech Synthesis
                    </p>
                </div>

                {/* Control Buttons */}
                <div className="flex space-x-3 mb-4">
                    <button
                        onClick={speakText}
                        disabled={isPlaying || !text.trim()}
                        className="px-4 py-2 bg-green-600 text-white rounded-md hover:bg-green-700 disabled:bg-gray-400 disabled:cursor-not-allowed"
                    >
                        {isPlaying ? 'üîä ƒêang ƒë·ªçc...' : '‚ñ∂Ô∏è ƒê·ªçc vƒÉn b·∫£n'}
                    </button>

                    {isPlaying && (
                        <button
                            onClick={stopSpeech}
                            className="px-4 py-2 bg-red-600 text-white rounded-md hover:bg-red-700"
                        >
                            ‚èπÔ∏è D·ª´ng
                        </button>
                    )}

                    <button
                        onClick={() => setText('')}
                        className="px-4 py-2 bg-gray-600 text-white rounded-md hover:bg-gray-700"
                    >
                        üóëÔ∏è X√≥a
                    </button>

                    {/* Test Lipsync Button */}
                    <button
                        onClick={() => {
                            console.log('üß™ Test lipsync manager...');
                            if (lipsyncManager) {
                                // Test cycle through different visemes
                                const testVisemes = [VISEMES.aa, VISEMES.E, VISEMES.I, VISEMES.O, VISEMES.U, VISEMES.PP, VISEMES.FF, VISEMES.SS, VISEMES.sil];
                                let index = 0;

                                const testInterval = setInterval(() => {
                                    if (index < testVisemes.length) {
                                        const viseme = testVisemes[index];
                                        lipsyncManager.viseme = viseme;
                                        lipsyncManager.features = {
                                            volume: viseme === VISEMES.sil ? 0 : 0.5,
                                            centroid: viseme === VISEMES.sil ? 0 : 3000,
                                            bands: Array(7).fill(viseme === VISEMES.sil ? 0 : 0.3),
                                            deltaBands: Array(7).fill(0)
                                        };
                                        console.log(`üé≠ Test viseme: ${viseme}`);
                                        index++;
                                    } else {
                                        clearInterval(testInterval);
                                        lipsyncManager.viseme = VISEMES.sil;
                                        lipsyncManager.features = { volume: 0, centroid: 0, bands: Array(7).fill(0), deltaBands: Array(7).fill(0) };
                                        console.log('‚úÖ Test ho√†n th√†nh');
                                    }
                                }, 500);
                            } else {
                                console.error('‚ùå LipsyncManager kh√¥ng t·ªìn t·∫°i');
                            }
                        }}
                        className="px-3 py-2 bg-purple-600 text-white rounded-md hover:bg-purple-700 text-sm"
                        disabled={isPlaying}
                    >
                        üß™ Test
                    </button>
                </div>

                {/* Status Display */}
                {isPlaying && enableFakeLipsync && (
                    <div className="p-3 bg-green-100 border border-green-200 rounded-md">
                        <div className="flex items-center space-x-2">
                            <div className="animate-pulse w-3 h-3 bg-green-500 rounded-full"></div>
                            <span className="text-sm font-medium text-green-700">
                                üîä ƒêang ph√°t speech v·ªõi fake lipsync simulation
                            </span>
                        </div>
                        <p className="text-xs text-green-600 mt-1">
                            Nh√¢n v·∫≠t 3D ƒëang m√¥ ph·ªèng chuy·ªÉn ƒë·ªông m√¥i theo t·ª´ng t·ª´: "{text.substring(0, 50)}{text.length > 50 ? '...' : ''}"
                        </p>
                        <div className="text-xs text-gray-500 mt-2 font-mono">
                            üîç Debug: M·ªü Console (F12) ƒë·ªÉ xem chi ti·∫øt viseme updates
                        </div>
                    </div>
                )}
            </div>

            {/* Info */}
            <div className="text-sm text-gray-600 bg-blue-50 p-3 rounded-md">
                <p className="mb-2">
                    <strong>üí° H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng:</strong>
                </p>
                <ul className="space-y-1 text-xs">
                    <li>üé§ <strong>Speech-to-Text:</strong> Ghi √¢m gi·ªçng n√≥i c·ªßa b·∫°n v√† chuy·ªÉn ƒë·ªïi th√†nh vƒÉn b·∫£n</li>
                    <li>üîä <strong>Text-to-Speech:</strong> Chuy·ªÉn vƒÉn b·∫£n th√†nh gi·ªçng n√≥i v·ªõi ƒë·ªìng b·ªô m√¥i</li>
                    <li>ü§ñ <strong>Fake Lipsync:</strong> Model 3D s·∫Ω m√¥ ph·ªèng chuy·ªÉn ƒë·ªông m√¥i theo n·ªôi dung</li>
                    <li>üåê <strong>ƒêa ng√¥n ng·ªØ:</strong> H·ªó tr·ª£ ti·∫øng Vi·ªát, ti·∫øng Anh v√† nhi·ªÅu ng√¥n ng·ªØ kh√°c</li>
                </ul>
                <p className="mt-2 text-xs">
                    <strong>‚öôÔ∏è Y√™u c·∫ßu:</strong> C·∫ßn kh·ªüi ƒë·ªông server API (python speech_api.py) v√† c·∫•u h√¨nh Google Cloud credentials
                </p>
            </div>

            {/* Debug Info */}
            <div className="p-2 bg-gray-50 border rounded-md text-xs">
                <div className="grid grid-cols-2 md:grid-cols-4 gap-2">
                    <div>
                        <strong>üé§ Speech Status:</strong> {isPlaying ? 'üîä ƒêang ph√°t' : '‚èπÔ∏è D·ª´ng'}
                    </div>
                    <div>
                        <strong>üéôÔ∏è Recording:</strong> {isRecording ? 'üî¥ ƒêang ghi' : '‚èπÔ∏è D·ª´ng'}
                    </div>
                    <div>
                        <strong>ü§ñ Fake Lipsync:</strong> {enableFakeLipsync ? '‚úÖ B·∫¨T' : '‚ùå T·∫ÆT'}
                    </div>
                    <div>
                        <strong>üåê API Server:</strong> {
                            apiServerStatus === 'ready' ? '‚úÖ S·∫µn s√†ng' :
                            apiServerStatus === 'no-credentials' ? '‚ö†Ô∏è Thi·∫øu credentials' :
                            '‚ùå Offline'
                        }
                    </div>
                </div>
                <div className="mt-2 grid grid-cols-2 gap-2">
                    <div>
                        <strong>üé≠ LipsyncManager:</strong> {lipsyncManager ? '‚úÖ OK' : '‚ùå L·ªói'}
                    </div>
                    <div>
                        <strong>üìù Text Length:</strong> {text.length} chars
                    </div>
                </div>
            </div>
        </div>
    );
};